[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jackson Hanson",
    "section": "",
    "text": "Portfolio for Jackson Hanson’s projects in Machine Learning"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Replication Study",
    "section": "",
    "text": "Abstract\nIn this Blog Post, we will examine racial disparities in healthcare algorithms. We will look at medical expenditures and patient risk scores to try and reproduce what Obermeyer et al. found in their 2019 study. We will use a polynomial Ridge regression to find the cost Black patients incur when compared to White Patients. We will find that on average, Black patients incur 77% of the medical costs of equally sick White patients which aligns with what Obermeyer et al. found. These findings suggest that cost-based risk algorithms may systematically underestimate the healthcare needs of Black patients.\n\nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Go through the columns and save the sames of the columns that end in '_elixhauser_tm1' \nchronic_condition_cols = [col for col in df.columns if col.endswith('_elixhauser_tm1')]\n\n# Add column for the percentile using qcut\ndf['risk_score_percentile'] = pd.qcut(df['risk_score_t'], 100, labels=False)\n\n# Number of chronic conditions for each patient\ndf['num_active_chronic_conditions'] = df[chronic_condition_cols].sum(axis=1)\n\n# Mean number of active chronic conditions WITHIN each risk score percentile\nsummary_df = df.groupby(['risk_score_percentile', 'dem_female', 'race'])[\n    'num_active_chronic_conditions'].mean().reset_index()\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n# Define color palette and marker styles for race:\npalette = {\"black\": \"darkblue\", \"white\": \"green\"}\nfixed_markers = {\"black\": \"o\", \"white\": \"s\"} \n\n# Loop through genders\nfor i, (gender_label, gender_value) in enumerate([(\"Male\", 0), (\"Female\", 1)]):\n    ax = axes[i]\n    subset = summary_df[summary_df[\"dem_female\"] == gender_value]\n\n    # Scatter plot:\n    sns.scatterplot(\n        data=subset,\n        x=\"num_active_chronic_conditions\",  # Now using the correctly calculated mean\n        y=\"risk_score_percentile\",\n        hue=\"race\",\n        style=\"race\",\n        palette=palette,\n        markers=fixed_markers,\n        s=60,\n        ax=ax\n    )\n\n    ax.set_xlabel(\"Mean Number of Chronic Illnesses\")\n    ax.set_title(gender_label)\n    ax.grid(True, linestyle=\"--\", alpha=0.6)\n\n# Set y-label on the left plot only\naxes[0].set_ylabel(\"Percentile Risk Score (from algorithm)\")\n\n# Place a common legend on the right side of the figure\nhandles, labels = axes[1].get_legend_handles_labels()\nfig.legend(handles, labels, title=\"Race\", loc=\"center right\")\n\n# Remove individual legends from each subplot\naxes[0].get_legend().remove()\naxes[1].get_legend().remove()\n\nplt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to fit the legend\nplt.show()\n\n\n\n\n\n\n\n\nThe graph shows that for the same number of chronic illnesses, Black patients (blue circles) tend to receive lower risk scores compared to White patients. Since risk scores are often used to determine eligibility for high-risk care management programs, this suggests that Patient A (Black) is less likely to be referred than Patient B (White), despite having the same health conditions. This gap implies that the algorithm may be underestimating the healthcare needs of Black patients, potentially due to its reliance on healthcare spending patterns rather than direct clinical measures. There looks like there is bias baked in here. As a result, Black patients may face reduced access to critical medical interventions, highlighting a racial bias in the risk assessment process that could contribute to inequities in healthcare treatment and outcomes.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Mean total medical expenditure per percentile of risk score\nrisk_score_summary = df.groupby(['risk_score_percentile', 'race'])['cost_t'].mean().reset_index()\n\n# Mean total medical expenditure per number of chronic conditions\nchronic_condition_summary = df.groupby(['gagne_sum_t', 'race'])['cost_t'].mean().reset_index()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n\n# Expenditure vs. Risk Score Percentile\nsns.scatterplot(\n    data=risk_score_summary,\n    x=\"risk_score_percentile\",\n    y=\"cost_t\",\n    hue=\"race\",\n    style=\"race\",\n    palette=palette,\n    markers = fixed_markers,\n    alpha=0.6,\n    ax=axes[0]\n)\naxes[0].set_xlabel(\"Percentile Risk Score\")\naxes[0].set_ylabel(\"Total Medical Expenditure\")\naxes[0].set_yscale(\"log\")\naxes[0].set_title(\"Total Medical Expenditure vs. Risk Score Percentile\")\naxes[0].grid(True, linestyle=\"--\", alpha=0.6)\n\n# Expenditure vs. Number of Chronic Illnesses\nsns.scatterplot(\n    data=chronic_condition_summary,\n    x=\"gagne_sum_t\",\n    y=\"cost_t\",\n    hue=\"race\",\n    style=\"race\",\n    palette=palette,\n    markers = fixed_markers,\n    alpha=0.6,\n    ax=axes[1]\n)\naxes[1].set_xlabel(\"Number of Chronic Illnesses\")\naxes[1].set_title(\"Total Medical Expenditure vs. Chronic Illnesses\")\naxes[1].set_yscale(\"log\") \naxes[1].grid(True, linestyle=\"--\", alpha=0.6)\n\n# Adjust legend position\nhandles, labels = axes[1].get_legend_handles_labels()\nfig.legend(handles, labels, title=\"Race\", loc=\"center right\")\n\n# Remove individual legends from subplots\naxes[0].get_legend().remove()\naxes[1].get_legend().remove()\n\n\nplt.show()\n\n\n\n\n\n\n\n\nThe graph reveals relationship between total medical expenditure and both risk score percentile and number of chronic illnesses. Again, it is obvious here that there is a disparity between black vs white. In the left panel, we see that as risk score percentiles increase, total medical expenditure rises. This makes sense, but when you take a look at black paitents, you see that Black patients consistently have lower expenditures than White patients at the same risk score percentile except for a few outliers. Similarly as the earleir plot, this suggests that the algorithm may underestimate the healthcare needs of Black patients or that they receive fewer medical interventions despite similar risk assessments.\nIn the right panel, a similar trend emerges: as the number of chronic illnesses increases, total medical expenditures also increase, but again, Black patients tend to have lower expenditures than White patients with the same number of chronic conditions. The exact cause of this difference could be caused by a few things like differences in healthcare access, treatment patterns, or systemic biases in how medical resources are dispersed.\n\nsubset_df = df[df[\"gagne_sum_t\"] &lt;= 5]\n(len(subset_df) / len(df)) * 100\n\n95.53952115447689\n\n\nOur decision to focus on patients with 5 or fewer chronic conditions is supported by the fact that they make up approximately 96% of the dataset. This ensures that our analysis remains representative of the majority of patients while minimizing the influence of extreme cases with very high chronic condition counts. Additionally, as the number of chronic conditions increases, the number of patients in those categories becomes much smaller, leading to increased variability in medical costs and potential instability in the model.\n\n# Remove patients with $0 medical cost (log(0) is undefined)\ndf = df[df[\"cost_t\"] &gt; 0]\n\n# Apply natural log transformation to medical cost\ndf[\"log_cost_t\"] = np.log(df[\"cost_t\"])\n\ndf[[\"cost_t\", \"log_cost_t\"]].head()\n\n\n\n\n\n\n\n\ncost_t\nlog_cost_t\n\n\n\n\n0\n1200.0\n7.090077\n\n\n1\n2600.0\n7.863267\n\n\n2\n500.0\n6.214608\n\n\n3\n1300.0\n7.170120\n\n\n4\n1100.0\n7.003065\n\n\n\n\n\n\n\n\n# Create a dummy variable for race\ndf[\"race_black\"] = (df[\"race\"] == \"black\").astype(int)\n\n\n# Define predictor variables (X) and target variable (y)\nX = df[[\"race_black\", \"gagne_sum_t\"]]  # Predictors: race and number of chronic illnesses\ny = df[\"log_cost_t\"]  # Target: log-transformed medical cost\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\nimport warnings\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\n# Step 2: Function to generate polynomial features efficiently\ndef add_polynomial_features(X, degree):\n    X_ = X.copy()\n    for j in range(1, degree):  # Start at degree 2 for additional features\n        X_[f\"poly_{j}\"] = (X_[\"gagne_sum_t\"] ** j).astype(\"float32\")  # Ensure memory-efficient float32\n    return X_\n\n# Step 3: Loop through polynomial degrees (1 to 11) and regularization strengths (10^k for k = -4 to 4)\ndegrees = range(1, 12)\nalphas = [10 ** k for k in range(-4, 5)]\n\nbest_score = float(\"inf\")\nbest_params = None\n\n# Suppress warnings during model fitting\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n\n    # Grid search over polynomial degrees and regularization strengths with memory optimization\n    for degree in degrees:\n        X_poly = add_polynomial_features(X, degree)  # Add polynomial features\n\n        for alpha in alphas:\n            model = Ridge(alpha=alpha)  # Ridge regression with given alpha\n            scores = cross_val_score(model, X_poly, y, scoring=\"neg_mean_squared_error\", cv=5) \n            mean_score = -np.mean(scores)  # Convert to positive MSE\n\n            if mean_score &lt; best_score:  # Track best combination\n                best_score = mean_score\n                best_params = (degree, alpha)\n\n# Display best parameters found\nprint(f\"Best Polynomial Degree: {best_params[0]}\")\nprint(f\"Best Regularization Strength (alpha): {best_params[1]}\")\nprint(f\"Best Cross-Validated MSE: {best_score:.4f}\")\n\nBest Polynomial Degree: 10\nBest Regularization Strength (alpha): 1\nBest Cross-Validated MSE: 1.5084\n\n\n\nbest_degree = best_params[0]\nbest_alpha = best_params[1]\n\nX_poly = add_polynomial_features(X, best_degree)\nfinal_model = Ridge(alpha=best_alpha)\nfinal_model.fit(X_poly, y)\n\nRidge(alpha=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Ridge?Documentation for RidgeiFittedRidge(alpha=1) \n\n\n\nX_poly.head()\n\n\n\n\n\n\n\n\nrace_black\ngagne_sum_t\npoly_1\npoly_2\npoly_3\npoly_4\npoly_5\npoly_6\npoly_7\npoly_8\npoly_9\n\n\n\n\n0\n0\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0\n3\n3.0\n9.0\n27.0\n81.0\n243.0\n729.0\n2187.0\n6561.0\n19683.0\n\n\n2\n0\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n0\n1\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n\n\n\n\n\n\n\nBecause race_black is the first column in our training data, we need the first coefficent because it corresponds to race_black.\n\nrace_black_coef = final_model.coef_[0]\nrace_black_coef\n\nnp.float64(-0.26704537754160196)\n\n\n\ncost_ratio = np.exp(race_black_coef) * 100\ncost_ratio\n\nnp.float64(76.56383278920148)\n\n\nI found a cost ratio of 77%. This suggests that on average, Black patients incur only 77% of the medical expenditures of White patients with the same number of chronic illnesses. I would say that this aligns with the results of Obermeyer et al., which identified that Black patients were assigned lower risk scores than White patients with the same level of medical complexity, leading to under-allocation of healthcare resources. This means that in industry, cost-based algorithms are used to determine patient risk, and they may systematically underestimate the healthcare needs of Black patients. This supports Obermeyer et al.’s argument that cost is an inadequate proxy for healthcare need and that such models must be adjusted to account for racial biases.\n\n\nDiscussion\nI conclude that what I replicated from Obermeyer et al demonstrates a racial bias that doesn’t satisfy the sufficiency criterion. Obermeyer et al. found that Black patients had more chronic illnesses than White patients at the same risk score, meaning that the model’s predictions were not equally valid across racial groups. This is a violation of sufficiency because the same predicted risk score does not correspond to the same true healthcare need across Black and White patients. As a result, Black patients are systematically assigned lower risk scores despite having a higher actual burden of illness. This leads to a reduced access to critical healthcare resources, where they only get about 77% of the spending as White patients. This study highlights the dangers of relying on cost-based algorithms for risk assessment."
  },
  {
    "objectID": "posts/Implementing Logistic Regression/index.html",
    "href": "posts/Implementing Logistic Regression/index.html",
    "title": "Blog Post 5 - Implementing Logistic Regression",
    "section": "",
    "text": "Logistic Regression Code: https://github.com/jacksonbhanson7/jacksonbhanson7.github.io/blob/main/posts/Implementing%20Logistic%20Regression/logistic.py\n\n%load_ext autoreload\n%autoreload 2\nfrom logistic import LogisticRegression, GradientDescentOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\nBlog Post 5 - Implementing Logistic Regression\n\n\nAbstract\nIn this project, we will implement logistic regression from scratch and train the model using gradient descent with and without momentum. We will evaluate performance on both synthetic data to illustrate overfitting, and on the famous Iris dataset. Throughout the project, we will track loss over iterations and draw meaningful conclusions on the effects of using momentum when optimizing lienar models.\n\n\nPart B\nFirst, let’s generate and vizualize some data.\n\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\n\n\ndef plot_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = 2*y[ix]-1, facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\n\nX, y = classification_data(noise = 0.1)\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nplot_data(X, y, ax)\n\n\n\n\n\n\n\n\nVanilla Gradient Descent\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss = 1.0\nloss_vec = []\n\n\n\nfor _ in range(400): \n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n\n    opt.step(X, y, alpha = 0.1, beta = 0)\n\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Logistic Regression Iteration (Updates Only)\", ylabel = \"loss\")\n\n\n\n\n\n\n\n\nIn this chunk, we perform gradient descent using logistic regression without momentum. The model is initialized and optimized over 400 iterations with a learning rate (alpha) of 0.1 and no momentum (beta = 0). At each iteration, the binary cross-entropy loss is computed and stored in a list. After training, the progression of the loss values over time is visualized using both a line plot and a scatter plot. We can see that the resulting graph shows a smooth, monotonic decrease in loss, indicating that the model is successfully learning and gradually minimizing the error over time.\n\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nplot_data(X, y, ax)\ndraw_line(LR.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n\n\n\n\n\n\n\n\nUsing Phil’s draw_line function, we can vizualize the desision boundary on this not noisy data.\nBenefits ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍of ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍momentum (same data)\n\n#NO MOMENTUM\nfig, axes = plt.subplots(2, 3, figsize=(14, 6))\nalphas = [0.01, 0.1, 0.25, 0.5, .8, .99]\n\nfor idx, alpha in enumerate(alphas):\n    model = LogisticRegression()\n    optimizer = GradientDescentOptimizer(model)\n\n    loss_vec = []\n    for _ in range(1000):\n        loss = model.loss(X, y)\n        loss_vec.append(loss.item())\n        optimizer.step(X, y, alpha=alpha, beta=0)\n\n    ax = axes.flatten()[idx]\n    ax.plot(loss_vec, color=\"slategrey\")\n    ax.scatter(torch.arange(len(loss_vec)), loss_vec, color=\"slategrey\")\n    ax.set_title(f\"α = {alpha}\")\n    ax.set_xlabel(\"Logistic Regression Iteration (Updates Only)\")\n    ax.set_ylabel(\"Loss\")\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#WITH MOMENTUM\nfig, axes = plt.subplots(2, 3, figsize=(14, 6))\nalphas = [0.01, 0.1, 0.25, 0.5, .8, .99]\n\nfor idx, alpha in enumerate(alphas):\n    model = LogisticRegression()\n    optimizer = GradientDescentOptimizer(model)\n\n    loss_vec = []\n    for _ in range(1000):\n        loss = model.loss(X, y)\n        loss_vec.append(loss.item())\n        optimizer.step(X, y, alpha=alpha, beta=0.9)\n\n    ax = axes.flatten()[idx]\n    ax.plot(loss_vec, color=\"slategrey\")\n    ax.scatter(torch.arange(len(loss_vec)), loss_vec, color=\"slategrey\")\n    ax.set_title(f\"α = {alpha}\")\n    ax.set_xlabel(\"Logistic Regression Iteration (Updates Only)\")\n    ax.set_ylabel(\"Loss\")\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIn this experiment, we compare the behavior of logistic regression on the same data, but tweak the alpha and beta values. This allows us to add momentum to the model. These figures compare the behavior of logistic regression trained with/without momentum across a range of learning rates. Each subplot shows the binary cross-entropy loss over 1000 iterations for a different value of alpha, from 0.01 to 0.99. The smaller learning rates lead to slow but steady convergence, requiring many iterations to reduce the loss. In contrast, larger learning rates dramatically accelerate convergence, reaching near-zero loss within just a few updates. Additionally, when momentum is added, there is signifcantly quicker convergence to near 0 loss.\nOverfitting\n\n# Generate the train and test datasets\nX_train, y_train = classification_data(n_points=30, noise=0.7, p_dims=100)\nX_test, y_test = classification_data(n_points=30, noise=0.7, p_dims=100)\n\n# Initialize your model and optimizer\nmodel = LogisticRegression()\noptimizer = GradientDescentOptimizer(model)\n\n\n\nloss = 1\n\n# Train for some iterations\n\nwhile True:  \n    train_preds = model.predict(X_train)\n    train_acc = (train_preds == y_train).float().mean().item()\n    if train_acc == 1:\n        break\n    optimizer.step(X_train, y_train, alpha=1, beta=0.99)\n\ntrain_preds = model.predict(X_train)\n\n# Evaluate on test data\ntest_preds = model.predict(X_test)\ntest_acc = (test_preds == y_test).float().mean().item()\n\nprint(f\"Train Accuracy: {train_acc:.2f}\")\nprint(f\"Test Accuracy: {test_acc:.2f}\")\n\nTrain Accuracy: 1.00\nTest Accuracy: 0.87\n\n\nIn this experiment, we take a look at what happens when we overfit data. We generate a high-dimensional dataset where the number of features (p_dim = 100) greatly exceeds the number of data points (n_points = 30). We generate two independent datasets using the same parameters: one for training and one for testing. A logistic regression model is trained on the training set using gradient descent with momentum (alpha = 1, beta = 0.99). The model continues to train until it achieves 100% training accuracy. After this loop breaks, we use this model to predict the other dataset (test). Notice that when we evaluate on the test data, accuracy drops to 87%. This gap between training and test performance illustrates overfitting. Here, the model that we trained has understoof the noise of the training data rather generalizing. This highlights the importance of evaluating models on unseen data, especially with high-dimensional data.\nPerformance ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍on ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍empirical ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍data\n\nfrom ucimlrepo import fetch_ucirepo \n  \n# fetch dataset \niris = fetch_ucirepo(id=53) \n  \n# data (as pandas dataframes) \nX = iris.data.features \ny = iris.data.targets \ny\n\n\n\n\n\n\n\n\nclass\n\n\n\n\n0\nIris-setosa\n\n\n1\nIris-setosa\n\n\n2\nIris-setosa\n\n\n3\nIris-setosa\n\n\n4\nIris-setosa\n\n\n...\n...\n\n\n145\nIris-virginica\n\n\n146\nIris-virginica\n\n\n147\nIris-virginica\n\n\n148\nIris-virginica\n\n\n149\nIris-virginica\n\n\n\n\n150 rows × 1 columns\n\n\n\nHere, we upload the famous iris dataset. The variable we are interested in predicting is not a yes/no column. It is a class of flower with three possible types of flower. There are three flowersL: Setosa, Virginica and Versicolor. The Iris dataset was first introduced by British statistician and biologist Ronald A. Fisher in 1936 as part of his paper The Use of Multiple Measurements in Taxonomic Problems. It contains measurements of sepal and petal length and width for three species of iris flowers and is commonly used as a benchmark dataset in classification problems.\n\n# Convert to binary classification: 1 if Setosa, 0 otherwise\ny_bin = (y['class'] == 'Iris-setosa').astype(int)\ny_bin\n\n0      1\n1      1\n2      1\n3      1\n4      1\n      ..\n145    0\n146    0\n147    0\n148    0\n149    0\nName: class, Length: 150, dtype: int64\n\n\nTo make this a binary prediction problem, we create a new column y_bin that is a 1 if the flower is Setosa, and 0 if it is not. So now we are trying to build a model that will successfully predict if a given flower is a Setosa or not.\n\nfrom sklearn.model_selection import train_test_split\n# Step 1: Hold out 20% of total data for testing\nX_temp, X_test, y_temp, y_test = train_test_split(X, y_bin, test_size=0.2)\n\n# Step 2: Take 25% of the remaining 80% for validation\nX_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25)\n\nWe utilize sci-kit-learn’s train_test_split function and a little fraction math to get a 60-20-20 breakdown for train-validation-testing data.\n\n# Convert everything to torch tensors *before* calling train_model\nX_train = torch.tensor(X_train.values, dtype=torch.float32)\nX_val   = torch.tensor(X_val.values, dtype=torch.float32)\nX_test  = torch.tensor(X_test.values, dtype=torch.float32)\n\ny_train = torch.tensor(y_train.values, dtype=torch.float32)\ny_val   = torch.tensor(y_val.values, dtype=torch.float32)\ny_test  = torch.tensor(y_test.values, dtype=torch.float32)\n\nHere, we convert all our data to torch tensors so that it works well with the classes that we’ve built.\n\nimport matplotlib.pyplot as plt\n\ndef train_model(X, y, X_val, y_val, alpha, beta, max_iter=50):\n    \n    model = LogisticRegression()\n    _ = model.predict(X)  # will call .score() and initialize weights\n    optimizer = GradientDescentOptimizer(model)\n\n    train_losses, val_losses = [], []\n    for i in range(max_iter):\n        train_losses.append(model.loss(X, y).item())\n        val_losses.append(model.loss(X_val, y_val).item())\n        optimizer.step(X, y, alpha=alpha, beta=beta)\n\n    return train_losses, val_losses, model\n\nThe train_model function performs trains a logistic regression model using gradient descent with a alpha, beta, and iterations parameters. It initializes the model weights, then repeatedly computes both the training loss and validation loss over time, storing them at each step. The optimizer updates the model weights using the specified hyperparameters. Finally, the function returns the sequence of training and validation losses along with the trained model, so that we can investigate it further after it is trained.\n\nimport matplotlib.pyplot as plt\n# Train with momentum\ntrain_loss_m, val_loss_m, model_m = train_model(X_train, y_train, X_val, y_val, alpha=0.5, beta=0.8)\n\n# Train without momentum\ntrain_loss_nom, val_loss_nom, model_nom = train_model(X_train, y_train, X_val, y_val, alpha=0.5, beta=0.0)\n\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Momentum subplot\naxes[0].plot(train_loss_m, label=\"Train Loss\")\naxes[0].plot(val_loss_m, label=\"Validation Loss\")\naxes[0].set_title(\"With Momentum\")\naxes[0].set_xlabel(\"Iteration\")\naxes[0].set_ylabel(\"Loss\")\naxes[0].legend()\n\n# No Momentum subplot\naxes[1].plot(train_loss_nom, label=\"Train Loss\")\naxes[1].plot(val_loss_nom, label=\"Validation Loss\")\naxes[1].set_title(\"Without Momentum\")\naxes[1].set_xlabel(\"Iteration\")\naxes[1].set_ylabel(\"Loss\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n# Evaluation on test data\ndef evaluate(model, X, y):\n    preds = model.predict(X)\n    acc = (preds == y).float().mean().item()\n    loss = model.loss(X, y).item()\n    return acc, loss\n\nacc_m, loss_m = evaluate(model_m, X_test, y_test)\nacc_nom, loss_nom = evaluate(model_nom, X_test, y_test)\n\nprint(f\"With Momentum — Test Accuracy: {acc_m:.2f}, Test Loss: {loss_m:.4f}\")\nprint(f\"Without Momentum — Test Accuracy: {acc_nom:.2f}, Test Loss: {loss_nom:.4f}\")\n\n\n\n\n\n\n\n\nWith Momentum — Test Accuracy: 1.00, Test Loss: 0.0001\nWithout Momentum — Test Accuracy: 1.00, Test Loss: 0.0170\n\n\nThis experiment compares the training and validation performance of logistic regression models trained with and without momentum. The loss plots show that the inclusion of momentum (beta = 0.9) results in a faster and more stable convergence. The loss curves on the left show a sharp drop in both training and validation loss, stabilizing near zero with minimal oscillation. Meanwhile, the model trained without momentum converges a little slower. Both models achieve perfect test accuracy, and the test loss is slightly lower for the model with momentum. Overall, momentum helps accelerate convergence and smooth out the optimization process without sacrificing performance.\n\n\nConclusion\nIn this blog post, we implemented logistic regression from scratch using torch and explored how gradient descent with and without momentum affects models. I tested my implementation on both synthetic and real-world (Iris) datasets, investigated overfitting behavior, and visualized loss curves to compare optimization. Through these experiments, I found that momentum can significantly speed up convergence and smooth the loss trajectory without sacrificing accuracy, especially in high-dimensional settings."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Abstract\nIn this study, we apply machine learning techniques to classify three penguin species—Adelie, Chinstrap, and Gentoo—using the famous Palmer Penguins dataset. We preprocess the data by handling missing values and encoding categorical variables, then explored feature relationships through visualizations. Then, we find the three most effective features for a Random Forest classifier and trained it using selected features. We were able to achieve 99% accuracy on the test set. This underscores the effectiveness of the chosen features and model in accurately distinguishing between the penguin species.\n\n\nExplore\nBefore we start exploring the data, we need to load in the Palmer’s Penguins Dataset and take a look at the data we are given.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nNow, we need to clean this data. First, we can see that there are some missing values. In this class, we haven’t learned how to impude the missing values yet, so I will just get rid of the rows that have N/A values. Then, I will use the provided code to “one-hot ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍encode” the categorical features. These categorical columns should now be True/False rather than Yes/No.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\nNow, I am going to merge the our target column with our features into a new dataset so that I can create visualizations easier.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndf = X_train.copy()\ndf[\"Species\"] = y_train.flatten().astype(int)\n\n\nfig, ax = plt.subplots(figsize=(6, 5))\nsns.scatterplot(data=df, x=\"Flipper Length (mm)\", y=\"Body Mass (g)\", hue=\"Species\", style=\"Species\", ax=ax)\nax.set(title=\"Body Mass vs. Flipper Length by Species\", xlabel=\"Flipper Length (mm)\", ylabel=\"Body Mass (g)\")\nhandles, _ = ax.get_legend_handles_labels()\nax.legend(handles, [\"Adelie\", \"Chinstrap\", \"Gentoo\"], title=\"Species\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis scatterplot shows the relationship between Flipper Length (mm) and Body Mass (g) by the three penguin species: Adelie, Chinstrap, and Gentoo. My first takeaway from this plot is that Gentoo penguins (represented by squares) have significantly higher higher body mass and longer flipper lengths than the other two species. Additionally, there is notable overlap between Adelie and Chinstrap penguins (represented by circles and X’s) in the middle of the graph. For a classification problem, this is a little alarming for me because this overlap suggests that Flipper Length and Body Mass alone won’t be able to reliably distinguish between Adelie and Chinstrap species. I may need to look for a different quantatative relationship to get to 100% accuracy.\n\n# map to have species name on x-axis rather than 0,1,2\nmap = {0: \"Adelie\", 1: \"Chinstrap\", 2: \"Gentoo\"}\n\n# Replace species numbers with names\ndf[\"Species\"] = df[\"Species\"].map(map)\nfig, ax = plt.subplots(figsize=(6, 5))\nsns.boxplot(data=df, x=\"Species\", y=\"Culmen Length (mm)\", ax=ax)\nax.set(title=\"Culmen Length by Species\", xlabel=\"Species\", ylabel=\"Culmen Length (mm)\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis boxplot illustrates the distribution of culmen length (mm) across the three penguin species. One observation is that Adelie penguins have the shortest culmen length by far. They have a median significantly lower than both Chinstrap and Gentoo penguins. Chinstrap penguins have the longest culmen length on average, with a higher IQR. Gentoo penguins tend to fall between the two but exhibit a slightly more compact distribution. This visualization reinforces the idea that culmen length could be a useful feature for distinguishing Adelie penguins from the other two species, but there may be some overlap between Chinstrap and Gentoo, so I’ll have to address this when I am searching for my 3 features.\n\n# Create a new 'Sex' column based on one-hot encoding to make aggregating table easier\ndf[\"Sex\"] = df[\"Sex_MALE\"].map({True: \"Male\", False: \"Female\"})\n\n\nsummary_table = df.groupby([\"Species\", \"Sex\"]).aggregate({\n    \"Culmen Length (mm)\": [\"mean\", \"std\"],\n    \"Culmen Depth (mm)\": [\"mean\", \"std\"],\n    \"Flipper Length (mm)\": [\"mean\", \"std\"],\n    \"Body Mass (g)\": [\"mean\", \"std\"]\n})\n\nsummary_table\n\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\n\nmean\nstd\nmean\nstd\nmean\nstd\nmean\nstd\n\n\nSpecies\nSex\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie\nFemale\n37.355769\n1.896686\n17.644231\n0.928928\n188.038462\n5.423122\n3353.365385\n264.576467\n\n\nMale\n40.451786\n2.449044\n19.064286\n1.048536\n192.839286\n6.893414\n4066.071429\n320.703367\n\n\nChinstrap\nFemale\n46.722581\n3.169933\n17.612903\n0.801558\n192.064516\n5.898788\n3523.387097\n294.953067\n\n\nMale\n51.312000\n1.633840\n19.256000\n0.779466\n200.480000\n6.325346\n4008.000000\n375.951570\n\n\nGentoo\nFemale\n45.455102\n1.971787\n14.210204\n0.536674\n212.836735\n3.466187\n4684.693878\n297.463948\n\n\nMale\n49.046512\n2.303760\n15.741860\n0.793495\n221.186047\n5.279141\n5481.976744\n302.830181\n\n\n\n\n\n\n\nThis table highlights consistent differences between male and female penguins across all three species, suggesting that sex could be a valuable feature for species classification. I noticed that male penguins tend to have larger body mass, culmen length, and flipper length compared to females within the same species. These differences are especially pronounced in Body Mass (g) and Flipper Length (mm), where males exhibit significantly higher mean values than females. Since the magnitude of these differences varies by species—for example, Gentoo males are much heavier than Chinstrap or Adelie. So maybe, sex in combination with other quantitative features, can help differentiate species. Given that some species, like Adelie and Chinstrap, show overlap in other features (like in the first graph), incorporating sex into the model may improve classification accuracy by providing an additional distinguishing factor.\n\n\nModel\nNow that I’ve done a little exploring of the data, it is time to determine which features will be predict the penguins in the “test” dataset. At a high level, I will iterate through every combination of 1 qualitative variable and 2 quantitative variables and use cross validation to determine which combination performs best within the training data.\n\nimport pandas as pd\nimport numpy as np\nfrom itertools import combinations\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nqualitative_features = [\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\", \"Clutch Completion_No\", \"Clutch Completion_Yes\", \"Sex_FEMALE\", \"Sex_MALE\"]\nquantitative_features = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]\n\n\nbest_features = None\nbest_score = 0\n\n# Try combinations of 1 qualitative + 2 quantitative features\nfor qual in qualitative_features:\n    for quant_combo in combinations(quantitative_features, 2):\n        selected_features = [qual] + list(quant_combo)\n\n        # Train a Random Forest\n        RF = RandomForestClassifier(random_state=7)\n        scores = cross_val_score(RF, X_train[selected_features], y_train, cv=5)\n\n        # Compute mean accuracy\n        mean_score = np.mean(scores)\n\n        # Track the best feature combination\n        if mean_score &gt; best_score:\n            best_score = mean_score\n            best_features = selected_features\n\n# Output the best feature set and corresponding accuracy\nbest_features, best_score\n\n(['Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)'],\n np.float64(0.9844645550527904))\n\n\nIn this block, I am trying all combnations of 1 qualitative and 2 quantiative features. For each combo, I am creating a Random Forest object (I chose lucky number 7 for reproducability) and using the cross_val_score function to see how the model does with these features. I am familiar with Random Forests from STAT0218 but I don’t remember how the hyperparameters work (like max_depth) so I didn’t tune those. I then took the vector of 5 cross-validation scores to gauge how each combination performed. I then updated the best score and selected features if they were the best so far. I found that the best three performing features were [‘Sex_MALE’, ‘Culmen Length (mm)’, ‘Culmen Depth (mm)’] which had an average accuracy of about 98% when I cross-validated. This is pretty in line with some of my findings from the explore phase.\n\n\nTesting\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\ncols = ['Culmen Length (mm)', 'Culmen Depth (mm)','Sex_MALE']\n\nRF = RandomForestClassifier(random_state=7)\nRF.fit(X_train[cols], y_train)\ntest_score = RF.score(X_test[cols], y_test)\ntest_score\n\n0.9852941176470589\n\n\nHere, I fit a random forest using the training data and evaluation it on the unseen test data. I was able to get ~99% accuracy. Now, let’s take a look at the decision boundaries.\n\nfrom matplotlib.patches import Patch\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\ncols = ['Culmen Length (mm)', 'Culmen Depth (mm)','Sex_MALE', \"Sex_FEMALE\"]\nRF.fit(X_train[cols], y_train)\n\nplot_regions(RF, X_train[cols], y_train)\n\n\n\n\n\n\n\n\nI used the plot_regions() function that we were given to show how the training data looks with a Random Forest Model and the feaures Culmen Length, Culmen Depth, and Sex. The boundaries for a Random Forest are a little funky but we can see how effective this model and these features are for classifying the penguins. The blue (Gentoo), red (Adelie), and green (Chinstrap) regions show how the model segments the graph. I notice that Gentoo are in the upper left showing that culmen depth might be the primary classfying in distinguishing. For Chinstrap and Adelie there is slightly more overlap. Some Chinstrap points appear in the red region. This suggests that while culmen depth helps differentiate Gentoo penguins, it may not be as reliable in distinguishing Adelie and Chinstrap.\nThe decision boundaries for males and females have the same general shape, but are different. This indicates that sex influences the classification. The boundaries for Adelie and Chinstrap penguins appear more distinct in females than in males, which may imply that culmen depth differences between these two species are more pronounced in female penguins. This reinforces why “Sex_MALE” was selected as an important feature—it helps refine the classification process and improves separation between species.\n\nplot_regions(RF, X_test[cols], y_test)\n\n\n\n\n\n\n\n\nI used the plot_regions() function that we were given to show how the decision boundaries on the testing data with my RF model using the feaures Culmen Length, Culmen Depth, and Sex. This model achieved 67/68 accuracy on the test data, meaning that every penguin was correctly except for 1. You can see the one error in my model on the test data where the Chinstrap penguin is in the Adelie section.\n\nfrom sklearn.metrics import confusion_matrix\ncols = ['Culmen Length (mm)', 'Culmen Depth (mm)','Sex_MALE']\nRF = RandomForestClassifier(random_state=7)\nRF.fit(X_train[cols], y_train)\n\ny_test_pred = RF.predict(X_test[cols])\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[31,  0,  0],\n       [ 0, 10,  1],\n       [ 0,  0, 26]])\n\n\nThe diagonal entires are the ones my model got correctly. The confusion matrix shows that the model performed well, correctly classifying 67 out of 68 test samples. The only misclassification occurred in the second row, where one Chinstrap penguin was mistakenly classified as Adelie. This suggests that while the model is effective, there may be some overlap in feature distributions between Chinstrap and Adelie, likely due to similarities in culmen depth or length.\n\n\nDiscussion\nThe successful classification of penguin species with perfect accuracy highlights the effectiveness of the Random Forest model and the feautres that were selected during this blog post. Notably, the inclusion of Sex as a feature proved crucial, as preliminary visualizations revealed overlapping measurements between Adelie and Chinstrap species in different features. Incorporating ‘Sex’ helped resolve this overlap, leading to clearer decision boundaries. This study demonstrates that through a clear classification pipeline, machine learning can effectively address classification problems in the real world."
  },
  {
    "objectID": "posts/Auditing-Bias/index.html#how-many-individuals-are-in-the-data",
    "href": "posts/Auditing-Bias/index.html#how-many-individuals-are-in-the-data",
    "title": "Blog Post 2 - Auditing Bias",
    "section": "1. How many individuals are in the data?",
    "text": "1. How many individuals are in the data?\nTo find the number of individual in the data, we can take a look at the number of rows.\n\ndf.shape[0]\n\n214480"
  },
  {
    "objectID": "posts/Auditing-Bias/index.html#of-these-individuals-what-proportion-have-target-label-equal-to-1-in-employment-prediction-these-would-correspond-to-employed-individuals.",
    "href": "posts/Auditing-Bias/index.html#of-these-individuals-what-proportion-have-target-label-equal-to-1-in-employment-prediction-these-would-correspond-to-employed-individuals.",
    "title": "Blog Post 2 - Auditing Bias",
    "section": "2. Of these individuals, what proportion have target label equal to 1? In employment prediction, these would correspond to employed individuals.",
    "text": "2. Of these individuals, what proportion have target label equal to 1? In employment prediction, these would correspond to employed individuals.\nBecause the employment vector is a column vector of booleans, the mean of that column will return the proportion of employed individuals in this dataset.\n\ndf[\"label\"].mean()\n\nnp.float64(0.4513474449832152)"
  },
  {
    "objectID": "posts/Auditing-Bias/index.html#of-these-individuals-how-many-are-in-each-of-the-groups",
    "href": "posts/Auditing-Bias/index.html#of-these-individuals-how-many-are-in-each-of-the-groups",
    "title": "Blog Post 2 - Auditing Bias",
    "section": "3. Of these individuals, how many are in each of the groups?",
    "text": "3. Of these individuals, how many are in each of the groups?\nWe can use the value_counts() method to get the number of people in each racial group.\n\ndf[\"group\"].value_counts()\n\ngroup\n1    165969\n2     20614\n8     10544\n6     10141\n9      5803\n3       836\n5       401\n7       158\n4        14\nName: count, dtype: int64"
  },
  {
    "objectID": "posts/Auditing-Bias/index.html#in-each-group-what-proportion-of-individuals-have-target-label-equal-to-1",
    "href": "posts/Auditing-Bias/index.html#in-each-group-what-proportion-of-individuals-have-target-label-equal-to-1",
    "title": "Blog Post 2 - Auditing Bias",
    "section": "4. In each group, what proportion of individuals have target label equal to 1?",
    "text": "4. In each group, what proportion of individuals have target label equal to 1?\nWe can use groupby() and mean() to get the proportions for each racial group.\n\n# Calculate the proportion of employed individuals in each racial group\ndf.groupby(\"group\")[\"label\"].mean()\n\ngroup\n1    0.455242\n2    0.416756\n3    0.431818\n4    0.357143\n5    0.461347\n6    0.499359\n7    0.430380\n8    0.466711\n9    0.353955\nName: label, dtype: float64"
  },
  {
    "objectID": "posts/Auditing-Bias/index.html#intersectional-trends",
    "href": "posts/Auditing-Bias/index.html#intersectional-trends",
    "title": "Blog Post 2 - Auditing Bias",
    "section": "5. Intersectional Trends",
    "text": "5. Intersectional Trends\nWe can take a look at the intersection of race and sex and how different combinations of the two effect employment. In this dataset 1 is male and 2 is female.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10,6))\nintersectional_df = df.groupby([\"group\", \"SEX\"])[\"label\"].mean().reset_index()\nsns.barplot(x=\"group\", y=\"label\", hue=\"SEX\", data=intersectional_df)\nplt.title(\"Employment Proportion by Race and Sex\")\nplt.xlabel(\"Race\")\nplt.ylabel(\"Proportion Employed\")\nplt.legend(title=\"Sex\")\nplt.show()\n\n\n\n\n\n\n\n\nThis bar chart displays the proportion of individuals employed across different racial groups, further broken down by sex. The two colors represent males (1.0) and females (2.0). Across most racial groups, there appears to be a consistent disparity in employment rates between males and females, with males generally having higher employment proportions than females. For example, in groups 4, 6, and 8, males show noticeably higher employment rates than females. However, in some cases, such as group 5, females have a higher employment rate than males. These disparities suggest that both race and sex impact employment outcomes, which could be an important factor to consider when evaluating fairness and bias in predictive models. Note that we are taking race out of our model as a feature, but this graph is interesting.\nNow that we’ve done some basic exploring of the data, we can start to build our model. I’ve decided to employ a RandomForest to try to predict employment status. To do this, I must tune the hyperparameter max_depth. In a Random Forest, tuning max_depth controls the maximum depth of each decision tree. The goal here is to try to balancing model complexity by preventing overfitting and underfitting with overly complex/simple trees.\nI created a for loop that tries different max_depths on Random Forest models. It uses 5 fold cross validation to test each max_depth and takes the mean of these 5 scores to determine which value performs the best.\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\n# Define a range of max_depth values to test\nmax_depth_values = [5, 10, 20, 30]  # Testing different depths\n\n\nbest_score = 0  # Initialize best score\nbest_depth = None  # Initialize best depth\n\n# Loop through different max_depth values\nfor depth in max_depth_values:\n    print(f\"Training Random Forest with max_depth={depth}\")\n\n    # Initialize Random Forest with current max_depth\n    RF = RandomForestClassifier(max_depth=depth, random_state=7)\n\n    # Perform cross-validation (5-fold)\n    scores = cross_val_score(RF, X_train, y_train, cv=5)\n\n    # Compute mean accuracy\n    mean_score = np.mean(scores)\n    print(f\"Mean CV Accuracy: {mean_score:.4f}\\n\")\n\n    # Track the best performing max_depth\n    if mean_score &gt; best_score:\n        best_score = mean_score\n        best_depth = depth\n\n# Print best depth and score\nprint(f\"Best max_depth: {best_depth} with accuracy: {best_score:.4f}\")\n\nTraining Random Forest with max_depth=5\nMean CV Accuracy: 0.8168\n\nTraining Random Forest with max_depth=10\nMean CV Accuracy: 0.8252\n\nTraining Random Forest with max_depth=20\nMean CV Accuracy: 0.8252\n\nTraining Random Forest with max_depth=30\nMean CV Accuracy: 0.8066\n\nBest max_depth: 20 with accuracy: 0.8252\n\n\nBased on the cross-validation results, max_depth = 20 is the optimal choice for the Random Forest model. At this depth, the model achieved the highest mean CV accuracy of 0.8252, indicating that it balances predictive power and generalization. While max_depth = 10 produced the same accuracy, deeper trees (max_depth = 30 and beyond) led to a decline in accuracy, suggesting potential overfitting.\nUsing max_depth = 20 ensures that the model captures important patterns in the data without becoming too complex. This depth allows the model to generalize well to unseen data while maintaining strong performance. The final model will now be trained using this optimized hyperparameter and evaluated on the test set.\nHere, I define and fit my Random Forest model. We can also extract the model predictions and store them in y_hat.\n\nfrom sklearn.ensemble import RandomForestClassifier\nRF = RandomForestClassifier(max_depth=20, random_state=7)\nRF.fit(X_train, y_train)\ny_hat = RF.predict(X_test)"
  },
  {
    "objectID": "posts/new-new-test-post copy/index.html",
    "href": "posts/new-new-test-post copy/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post copy/index.html#math",
    "href": "posts/new-new-test-post copy/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/Implementing the Perceptron Algorithm/index.html",
    "href": "posts/Implementing the Perceptron Algorithm/index.html",
    "title": "Blog Post 4 - Implementing the Perceptron Algorithm",
    "section": "",
    "text": "Perceptron Code: https://github.com/jacksonbhanson7/jacksonbhanson7.github.io/blob/main/posts/Implementing%20the%20Perceptron%20Algorithm/perceptron.py\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\n\nBlog Post 4 - Implementing the Perceptron Algorithm\n\n\nAbstract\nIn this blog post, we will explore the perceptron algorithm and its minibatch variant through a series of experiments on different datasets. We begin by implementing the core perceptron update rule, including support for minibatch update, and validating our implementation on both linearly separable and non-separable data. Towards the end, we will tweak with batch size (k) and learning rate (alpha), and demonstrate how minibatch perceptron is different than the origioal perceptron alog. Visualizations of loss, score trajectories, and desision boundaries are included throughout the post.\n\n\nPart B\nFirst, let’s generate and vizualize some linearly separable data in 2d. We can use the perceptron_data function to do so.\n\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    \n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = 2*y[ix]-1, facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nX, y = perceptron_data()\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\nClearly this data is linearly separable, so Perceptron is guarenteed to find a separation line.\nNow, let’s vizualize the loss over the course of the algorithm. Because we know this data is linearly separable, we can run this dangerous while loop because we know it will converge.\n\nfrom perceptron import Perceptron, PerceptronOptimizer\ntorch.manual_seed(1234567)\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n\n# for keeping track of loss values\nloss_vec = []\n\nn = X.size()[0]\n\nwhile loss &gt; 0: # dangerous -- only terminates if data is linearly separable\n    \n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    # pick a random data point\n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    \n    # perform a perceptron update using the random data point\n    opt.step(x_i, y_i)\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\n\n\n\n\n\n\n\nIn this section, we set up a Perceptron training loop with one update per iteration. The model and optimizer are initialized, and a loss vector is used to track how performance changes over time. In each iteration, a random data point is selected and passed to opt.step(), which performs the Perceptron update if the point is misclassified. The loss is calculated and stored at each step to visualize how quickly the model converges on linearly separable data.\nWe can use Phil’s draw_line function to see some desision boundaries and how they progress as iterations increase.\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\nNow let’s see how the desision boundaries evolve using the Phil’s code from lecture notes.\n\ntorch.manual_seed(1234567)\n\n# initialize a perceptron \np = Perceptron()\nopt = PerceptronOptimizer(p)\np.loss(X, y)\n\n# set up the figure\nplt.rcParams[\"figure.figsize\"] = (7, 5)\nfig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\nmarkers = [\"o\", \",\"]\nmarker_map = {-1 : 0, 1 : 1}\n\n# initialize for main loop\ncurrent_ax = 0\nloss = 1\nloss_vec = []\n\nwhile loss &gt; 0:\n    ax = axarr.ravel()[current_ax]\n\n    # save the old value of w for plotting later\n    old_w = torch.clone(p.w)\n\n    # make an optimization step -- this is where the update actually happens\n    # now p.w is the new value \n\n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    local_loss = p.loss(x_i, y_i).item()\n\n    if local_loss &gt; 0:\n        opt.step(x_i, y_i)\n    # if a change was made, plot the old and new decision boundaries\n    # also add the new loss to loss_vec for plotting below\n    if local_loss &gt; 0:\n        plot_perceptron_data(X, y, ax)\n        draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n        loss = p.loss(X, y).item()\n        loss_vec.append(loss)\n        draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n        ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[2*(y[i].item())-1]])\n        # draw_line(w, -10, 10, ax, color = \"black\")\n        ax.set_title(f\"loss = {loss:.3f}\")\n        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n        current_ax += 1\nplt.tight_layout()\n\n\n\n\n\n\n\n\nThis chunk visualizes how the Perceptron decision boundary evolves over training. Again, in each iteration, a random data point is selected and the model updates only if the point is misclassified, allowing us to see the weight changes. The subplot grid shows the dataset, the previous decision boundary, and the new decision boundary after each update. This allows us to see how the Perceptron gradually converges on the correct boundary for linearly separable data.\nNow, I’ve created a new data-generating function that will flip the class of a fraction of points. This will make the data messier so that we can experiment with some non linarly separable data.\n\ndef perceptron_data_with_label_noise(n_points=300, noise=0.2, p_dims=2, flip_frac=0.1):\n    y = (torch.arange(n_points) &gt;= int(n_points / 2)).int()\n    X = y[:, None] + torch.normal(0.0, noise, size=(n_points, p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    n_flip = int(flip_frac * n_points)\n    flip_indices = torch.randperm(n_points)[:n_flip]\n    y[flip_indices] = 1 - y[flip_indices]  \n\n    return X, y\n\n\nThis function I created generates the same classification data, but flips the labels with a fraction of the points. I did this so that I could create data that I know is not linearly separable.\n\nX, y = perceptron_data_with_label_noise(300, noise=0.2, p_dims = 2, flip_frac=0.1)\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 2), ylim = (-1, 2))\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\nNotice how there is overlap between the blue and orange points in this data.\n\nfrom perceptron import Perceptron, PerceptronOptimizer\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n\n# for keeping track of loss values\nloss_vec = []\nscore_vec = []\n\nn = X.size()[0]\n\niterations = 0\n\nwhile loss &gt; 0 and iterations &lt; 1000: # dangerous -- only terminates if data is linearly separable\n    \n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    avg_score = p.score(X).mean()\n    score_vec.append(avg_score)\n\n    \n    # pick a random data point\n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    \n    # perform a perceptron update using the random data point\n    opt.step(x_i, y_i)\n    iterations += 1\n\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 2), ylim = (-1, 2))\nplot_perceptron_data(X, y, ax)\ndraw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n\n\n\n\n\n\n\n\nNow we are doing the same training hoop on non-linearly separable data. The model is trained while both loss and classification score are recorded after each update. In addition to tracking loss, we are also keeping track of the scores for each iteration after the weights change. This allows us track model performance and observe how it stabilizes over time.\nThis is the desision boundary after 1000 iterations. Because this data is not lienarly separable, loss never got to 0.\n\nplt.plot(score_vec)\nplt.xlabel(\"Perceptron Iteration (Updates Only)\")\nplt.ylabel(\"Average Score\")\nplt.title(\"Perceptron Score Over Time\")\n\nText(0.5, 1.0, 'Perceptron Score Over Time')\n\n\n\n\n\n\n\n\n\nWe can see that the score fluctuates heavily across iterations because our data is very noisy (by design) indicating and that the algorithm struggles to consistently separate the data. The lack of convergence or stabilization in the score confirms the non-linearly separable nature of the dataset.\nNow, let’s run the perceptron algorithm on data that isn’t 2d. I am setting p_dims to 5 instead of 2 in this experiment.\n\n# Generate data with 5 features (plus bias)\nX, y = perceptron_data(n_points=300, noise=0.3, p_dims=5)  # no noise so it’s linearly separable\n\n# Perceptron setup\np = Perceptron()\nopt = PerceptronOptimizer(p)\n\nloss = 1.0\nloss_vec = []\nscore_vec = []\n\nn = X.size()[0]\niterations = 0\n\n# Training loop\nwhile loss &gt; 0 and iterations &lt; 1000:\n    loss = p.loss(X, y)\n    loss_vec.append(loss)\n\n    avg_score = p.score(X).mean()\n    score_vec.append(avg_score)\n    \n    # Pick a random example\n    i = torch.randint(n, size=(1,))\n    x_i = X[i, :]\n    y_i = y[i]\n\n    \n\n    # Perform perceptron update\n    opt.step(x_i, y_i)\n    iterations += 1\n\nIn this training loop, the Perceptron is applied to a clean 5-dimensional dataset with no label flipping. The model’s average classification score is tracked over time using a simple loop. Because the data can be perfectly separated, the score stabilizes and remains consistently high.\n\nplt.plot(score_vec)\nplt.xlabel(\"Perceptron Iteration (Updates Only)\")\nplt.ylabel(\"Average Score\")\nplt.title(\"Perceptron Score Over Time\")\n\nText(0.5, 1.0, 'Perceptron Score Over Time')\n\n\n\n\n\n\n\n\n\nThe score plot shows that the average score becomes more stable and consistently positive over the training period. This suggests that the perceptron is learning a reliable decision boundary. Given that the data was generated without label noise and the score stabilizes quickly, I believe the dataset is linearly separable.\n\n\nPart C\nNow that we’ve tweaked perceptron.py, let’s do some minibatch experiment.\n\n# Function to run minibatch perceptron\ndef run_minibatch_experiment(X, y, k, alpha=1.0, max_iter=1000):\n    p = Perceptron()\n    opt = PerceptronOptimizer(p, alpha=alpha)\n    loss_vec = []\n\n    n = X.shape[0]\n    iterations = 0\n    loss = 1.0\n\n    while loss &gt; 0 and iterations &lt; max_iter:\n        loss = p.loss(X, y)\n        loss_vec.append(loss.item())\n\n        # Get random minibatch\n        ix = torch.randperm(n)[:k]\n        x_i = X[ix, :]\n        y_i = y[ix]\n\n        opt.step(x_i, y_i)\n        iterations += 1\n\n    return loss_vec\n\n\n\n# Experiment 1: k = 1 (standard perceptron)\nX1, y1 = perceptron_data()\nloss_k1 = run_minibatch_experiment(X1, y1, k=1)\n\n# Experiment 2: k = 10\nX2, y2 = perceptron_data()\nloss_k10 = run_minibatch_experiment(X2, y2, k=10)\n\n# Experiment 3: k = n with non-linearly separable data\nX3, y3 = perceptron_data_with_label_noise(flip_frac=.1)\nloss_kn = run_minibatch_experiment(X3, y3, k=X3.shape[0], alpha=0.0001, max_iter=20000)  # note: smaller alpha!\n\n\nfig, axs = plt.subplots(1, 3, figsize=(15, 4))\n\naxs[0].plot(loss_k1)\naxs[0].set_title(\"Minibatch Perceptron (k=1)\")\naxs[0].set_xlabel(\"Iterations\")\naxs[0].set_ylabel(\"Loss\")\n\naxs[1].plot(loss_k10)\naxs[1].set_title(\"Minibatch Perceptron (k=10)\")\naxs[1].set_xlabel(\"Iterations\")\n\naxs[2].plot(loss_kn)\naxs[2].set_title(\"Minibatch Perceptron (k=n, noisy data)\")\naxs[2].set_xlabel(\"Iterations\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis code defines and runs a generalized training function for minibatch Perceptron, which selects k random points per update instead of one. The function is used to compare three scenarios: standard Perceptron (k=1), a minibatch of size 10, and a full-batch update on noisy data. Each run records the loss over time to visualize how quickly and stably the model learns under different conditions. The plots show that increasing k improves convergence speed this data, and that full-batch updates can still reduce loss even on this dataset with a small enough learning rate.\n\n\nPart D\ngrad() walkthrough: This function implements the update for the minibatch perceptron algorithm. It begins by converting binary class labels y into the values {-1, 1} using y_hat = 2 * y - 1. The model computes a score s for each data point using the current weights w, and checks which points are misclassified by evaluating whether s * y_hat &lt; 0. For the misclassified points, it computes their contribution to the weight update as - y_hat * x, while assigning no contribution from correctly classified points. These individual updates are then averaged across the minibatch using .mean(dim=0), aligning with the update rule described in the course: averaging the adjustments from misclassified examples and scaling by the learning rate α. This function mirrors the logic of Equation (1) from the instructions.\nRuntime: The runtime complexity of a single iteration of the standard perceptron algorithm is O(p), where p is the number of features, because each update involves a dot product between the weight vector and a single data point. In this case, the time complexity does not depend on n, the total number of data points, since the perceptron updates using only one random point per iteration. However, in the minibatch perceptron, each iteration uses k points, so the complexity becomes O(kp). When k = n, meaning a full batch is used, the complexity becomes O(np). Thus, while the standard perceptron scales only with the number of features, the minibatch version introduces a dependence on the batch size.\n\n\nConclusion\nIn conclusion, this blog post explored the perceptron algorithm and its ability to find linear decision boundaries through iterative updates based on classification errors. We implemented the core update rule and visualized how the algorithm learns over time across different settings and datasets. In the latter part of the project, we extended the perceptron to support minibatch updates, which allowed us to average updates across multiple examples, improving stability and enabling convergence even in the presence of noise. These experiments highlighted both the strengths and limitations of the perceptron and provided a foundation for understanding more advanced linear classifiers."
  },
  {
    "objectID": "posts/Sparse Kernel Machines/index.html",
    "href": "posts/Sparse Kernel Machines/index.html",
    "title": "Blog Post 6 - Sparse Kernel Machines",
    "section": "",
    "text": "Sparse Kernel Regression Code: https://github.com/jacksonbhanson7/jacksonbhanson7.github.io/blob/main/posts/Sparse%20Kernel%20Machines/logistic2.py\n\n%load_ext autoreload\n%autoreload 2\nfrom logistic2 import SparseKernelLogisticRegression, GradientDescentOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\nBlog Post 6 - Sparse Kernel Machines\n\n\nAbstract\nIn this post, we will explore sparse kernel logistic regression. We implement the model in logistic2.py using torch, and conduct experiments tweaking the hyperparameters for this model. We will demonstrate how varying the regularization parameter λ encourages sparsity in the learned model, often requiring only a small subset of training examples to define the decision boundary. We also show how the γ affects the model’s complexity and decision boundary shape. Finally, we use ROC curves to illustrate how poor tuning of γ can lead to overfitting, emphasizing the importance of hyperparameter selection in kernelized models.\n\n\nPart B\nThis function rbf_kernel computes the Radial Basis Function (RBF) kernel. I got this code chunk from Phil. This function takes in between two input matrices X_1 and X_2 and measures the similarity between each pair of points from the two sets. The gamma parameter controls the “width” of the function. Essentially, it takes the original input space into a higher-dimensional feature space, enabling the model to learn nonlinear decision boundaries.\n\nimport torch\ndef rbf_kernel(X_1, X_2, gamma):\n    return torch.exp(-gamma*torch.cdist(X_1, X_2)**2)\n\nFirst, let’s generate and vizualize some linearly-separable-ish data.\n\nimport torch \nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    # X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    X = X - X.mean(dim = 0, keepdim = True)\n    return X, y\n\n\ndef plot_classification_data(X, y, ax):\n    assert X.shape[1] == 2, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -1, vmax = 2, alpha = 0.8, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data(n_points = 100, noise = 0.4)\nplot_classification_data(X, y, ax)\n\n\n\n\n\n\n\n\nNow let’s run Sparse Kernal Logistic Regression. Here, we are initializing a SparseKernelLogisticRegression object, passing in our kernel function, along with parameters lam and gamma. Then, we are fitting the model with 500,000 epochs and a learning rate of 0.0001.\n\nKR = SparseKernelLogisticRegression(rbf_kernel, lam = 0.1, gamma = 1)\nKR.fit(X, y, m_epochs = 500000, lr = 0.0001)\n\n\n(1.0*(KR.a &gt; 0.001)).mean()\n\ntensor(0.0600)\n\n\nBy taking the mean of the weights, we can see that many of the weights are zero because the mean is so small.\nNow let’s use Phil’s function to visualize the desision boundary that we came up with. Notice here that the non-zero weights are shaded darker. This demonstrates that the model is acting in a way that makes sense because the darker points (ones with non-zero weights) are all very close to the “center” of the general grouping for points of their type.\n\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:,0].min() - 0.2, X[:,0].max() + 0.2, 101)\nx2 = torch.linspace(X[:,1].min() - 0.2, X[:,1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing='ij')\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim = 1)\n\npreds = KR.score(X_)\npreds = 1.0*torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(X1, X2, preds, origin = \"lower\", cmap = \"BrBG\", \nvmin = 2*preds.min() - preds.max(), vmax = 2*preds.max() - preds.min()\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")\n# ax.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")\n\n\n\n\n\n\n\n\nNow, let’s see what happens when we make lamda much larger. Here I am setting lam to 10, and keeping gamma at 1.\n\nKR = SparseKernelLogisticRegression(rbf_kernel, lam=10, gamma=1)\nKR.fit(X, y, m_epochs=500000, lr=0.0001)\n\n\n(1.0*(KR.a &gt; 0.001)).mean()\n\ntensor(0.0100)\n\n\nAfter taking the mean of the weights, we can see that very very few of the weights are non-zero. Let’s use the same plotting function to see which point this non-zero weight coinsides with.\n\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:,0].min() - 0.2, X[:,0].max() + 0.2, 101)\nx2 = torch.linspace(X[:,1].min() - 0.2, X[:,1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing='ij')\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim = 1)\n\npreds = KR.score(X_)\npreds = 1.0*torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(X1, X2, preds, origin = \"lower\", cmap = \"BrBG\", \nvmin = 2*preds.min() - preds.max(), vmax = 2*preds.max() - preds.min()\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")\n# ax.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")\n\n\n\n\n\n\n\n\nWe can see that this model only has one point at (.9, .5) with a non-zero weight.\nNow, let’s see what happens when we change the value of gamma. Here we are storing different values of gamma in the gammas list and iterating through them. At each step in the loop, we are training a new model with a different choice of gamma, initializing a new Sparse Kernel Model, fitting the points, and visualizing the desision boundary using Phil’s function.\n\ngammas = [0.01, 0.1, 1, 10, 50, 100]\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))  # 2 rows × 3 columns\naxes = axes.flatten()  # So we can index with a single loop\n\nfor i, gam in enumerate(gammas):\n    KR = SparseKernelLogisticRegression(rbf_kernel, lam=0.1, gamma=gam)\n    KR.fit(X, y, m_epochs=500000, lr=0.0001)\n    ix = torch.abs(KR.a) &gt; 0.001\n\n    x1 = torch.linspace(X[:, 0].min() - 0.2, X[:, 0].max() + 0.2, 101)\n    x2 = torch.linspace(X[:, 1].min() - 0.2, X[:, 1].max() + 0.2, 101)\n    X1, X2 = torch.meshgrid(x1, x2, indexing='ij')\n\n    x1 = X1.ravel()\n    x2 = X2.ravel()\n    X_ = torch.stack((x1, x2), dim=1)\n\n    preds = KR.score(X_)\n    preds = 1.0 * torch.reshape(preds, X1.size())\n\n    ax = axes[i]\n    ax.contourf(X1, X2, preds, origin=\"lower\", cmap=\"BrBG\",\n                vmin=2*preds.min() - preds.max(),\n                vmax=2*preds.max() - preds.min())\n    plot_classification_data(X, y, ax)\n    ax.scatter(X[ix, 0], X[ix, 1], facecolors=\"none\", edgecolors=\"black\")\n    ax.set_title(f\"gamma = {gam}\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIt is obvious here that as gamma increases, the boundaries get much more wiggly. This is alerting me to the fact that when gamma is large, we are at risk of overfitting. In the gamma = 100 example, the boundaries are very, very, complex. This wouldn’t generalize well to unseen testing data.\nNow, let’s see how the model performs on non-linear data. Here we are using the sci-kit-learn make_moons function. After generating the data, we convert the data to torch tensors so they will work with our model. Then we can see what the points look like on a plot below.\n\nfrom sklearn.datasets import make_moons\nX, y = make_moons(n_samples=100, noise=0.2)\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32)\nfig, ax = plt.subplots(1, 1)\nplot_classification_data(X, y, ax)\n\n\n\n\n\n\n\n\nFrom what I have seen in the past two experiments, I decided to use lam = .1 and gamma = 5. In the two previous experiments, funky things happened when these parameters were large, so I chose some safe values.\n\nKR = SparseKernelLogisticRegression(rbf_kernel, lam=.1, gamma=5)\nKR.fit(X, y, m_epochs=500000, lr=0.0001)\n\n\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:,0].min() - 0.2, X[:,0].max() + 0.2, 101)\nx2 = torch.linspace(X[:,1].min() - 0.2, X[:,1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing='ij')\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim = 1)\n\npreds = KR.score(X_)\npreds = 1.0*torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(X1, X2, preds, origin = \"lower\", cmap = \"BrBG\", \nvmin = 2*preds.min() - preds.max(), vmax = 2*preds.max() - preds.min()\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")\n# ax.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")\n\n\n\n\n\n\n\n\nAfter fitting the model and visualizing the boundaries, it looks like this model was able to correctly catch the moon shapes. Let’s quantify how well the model performed.\n\ny_hat = KR.predict(X)\nacc = (y_hat == y).float().mean().item()\nprint(f\"Training Accuracy: {acc:.3f}\")\n\nTraining Accuracy: 0.930\n\n\nOn the training data, the model performed with 93% accuracy.\n\n\nPart C\nIn this experiement, we are aiming to demonstrate overfitting by changing the gamma values. Below, we generate two independent moon-like shapes using the make_moons function from earlier. Again, we convert the data to torch tensors.\n\nX_train, y_train = make_moons(n_samples=200, noise=0.5)\nX_test, y_test = make_moons(n_samples=200, noise=0.5)\n\nX_train = torch.tensor(X_train, dtype=torch.float32)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32)\n\n/var/folders/3p/_jcm4hhd7rj59x0q1n5_8yrw0000gn/T/ipykernel_10973/1084629014.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y = torch.tensor(y, dtype=torch.float32)\n\n\nHere we are fitting two different models. One with a moderate gamma (1) and one with a high gamma (100).\n\nmodel_good = SparseKernelLogisticRegression(rbf_kernel, lam=0.5, gamma=1)\nmodel_overfit = SparseKernelLogisticRegression(rbf_kernel, lam=0.5, gamma=100)\n\nmodel_good.fit(X_train, y_train, m_epochs=500000, lr=0.01)\nmodel_overfit.fit(X_train, y_train, m_epochs=500000, lr=0.01)\n\n\nimport matplotlib.pyplot as plt\nimport torch\n\n# Compute important values for the grid\nx1 = torch.linspace(X_train[:,0].min() - 0.2, X_train[:,0].max() + 0.2, 101)\nx2 = torch.linspace(X_train[:,1].min() - 0.2, X_train[:,1].max() + 0.2, 101)\nX1, X2 = torch.meshgrid(x1, x2, indexing='ij')\nx1 = X1.ravel()\nx2 = X2.ravel()\nX_ = torch.stack((x1, x2), dim=1)\n\n# Compute scores\npreds_good = model_good.score(X_).reshape(X1.size())\npreds_overfit = model_overfit.score(X_).reshape(X1.size())\n\n# Plot side-by-side\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Good model\naxes[0].contourf(X1, X2, preds_good, origin=\"lower\", cmap=\"BrBG\", \n                 vmin=2*preds_good.min() - preds_good.max(), \n                 vmax=2*preds_good.max() - preds_good.min())\nplot_classification_data(X_train, y_train, axes[0])\naxes[0].set_title(\"gamma=1 (Good Fit)\")\n\n# Overfit model\naxes[1].contourf(X1, X2, preds_overfit, origin=\"lower\", cmap=\"BrBG\", \n                 vmin=2*preds_overfit.min() - preds_overfit.max(), \n                 vmax=2*preds_overfit.max() - preds_overfit.min())\nplot_classification_data(X_train, y_train, axes[1])\naxes[1].set_title(\"gamma=100 (Overfit)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe decision boundary on the left (γ = 1) captures the general structure of the data well without fitting to noise, while the boundary on the right (γ = 100) is highly irregular and overly complex. This demonstrates overfitting, where the model memorizes the training data at the expense of generalization.\n\ntrain_scores_good = model_good.score(X_train)\ntest_scores_good = model_good.score(X_test)\n\ntrain_scores_overfit = model_overfit.score(X_train)\ntest_scores_overfit = model_overfit.score(X_test)\n\n\nfrom sklearn.metrics import roc_curve, auc\n\ndef plot_roc(y_true, scores, label):\n    fpr, tpr, _ = roc_curve(y_true, scores.detach().numpy())\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label=f\"{label} (AUC = {roc_auc:.2f})\")\n\nplt.figure(figsize=(8,6))\n\n# Good model\nplot_roc(y_train, train_scores_good, \"Train - gamma=1\")\nplot_roc(y_test, test_scores_good, \"Test - gamma=1\")\n\n# Overfit model\nplot_roc(y_train, train_scores_overfit, \"Train - gamma=100\")\nplot_roc(y_test, test_scores_overfit, \"Test - gamma=100\")\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve - Demonstrating Overfitting\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nThis ROC curve clearly illustrates overfitting through a comparison of model performance across different values of γ. The dashed line is a benchmark for random guessing the class of a point. When γ = 1, the AUC values for both training (0.80) and testing (0.77) are high and closely aligned, indicating a good fit with strong generalization. In contrast, with γ = 100, the training AUC (0.51) is already low, and the test AUC (0.49) is even worse—approaching random guessing. This drastic drop in performance, especially on unseen data, reveals that the model has overfit to noise in the training set, failing to capture the underlying data pattern in a generalizable way.\n\n\nConclusion\nIn this blog post, we implemented a sparse kernel logistic regression model using an RBF kernel, allowing us to model nonlinear patterns. We explored how tuning the hyperparameters λ and γ affected model complexity and generalization. Through experiments, we showed that a large λ forces most weights to zero, reducing reliance on unnecessary data points. We also visualized how varying γ shapes the decision boundary and demonstrated how an overly large γ can lead to overfitting. ROC curves further revealed the dangers of overfitting, emphasizing the need to balance model expressiveness with generalization."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jackson Hanson CSCI 0451 Blog",
    "section": "",
    "text": "Blog Post 6 - Sparse Kernel Machines\n\n\n\n\n\nImplement Sparse Kernel Regression and conduct experiments with different data\n\n\n\n\n\nApr 22, 2025\n\n\nJackson Hanson\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 5 - Implementing Logistic Regression\n\n\n\n\n\nImplement the Logistic Regression algorithm with and without momentum\n\n\n\n\n\nMar 31, 2025\n\n\nJackson Hanson\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 4 - Implementing the Perceptron Algorithm\n\n\n\n\n\nImplement the Perceptron algorithm and its minibatch variant\n\n\n\n\n\nMar 24, 2025\n\n\nJackson Hanson\n\n\n\n\n\n\n\n\n\n\n\n\nReplication Study\n\n\n\n\n\nExamine racial disparities in healthcare algorithms\n\n\n\n\n\nMar 10, 2025\n\n\nJackson Hanson\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 2 - Auditing Bias\n\n\n\n\n\nAnalyze whether RF model produced consisten predictions across races\n\n\n\n\n\nMar 4, 2025\n\n\nJackson Hanson\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nUse ML techniques to classify Palmer Penguins\n\n\n\n\n\nFeb 24, 2025\n\n\nJackson Hanson\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  }
]