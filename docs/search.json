[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jackson TEST",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "First, I am going to load in the Penguin Data and take a look at the data we are given.\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\nNow, I’ll use the code that was provided to one-hot ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍encode the categorical features. I’ve also decided to remove rows the have N/A because we haven’t learned how to impude the missing values yet.\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\ny_train\n\narray([1, 1, 2, 2, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 1, 2, 0, 2, 2, 2, 2, 0,\n       0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 2, 1, 1, 2, 2, 1, 0,\n       0, 2, 2, 1, 2, 2, 1, 2, 0, 0, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 2, 2,\n       0, 0, 0, 2, 2, 2, 0, 1, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0,\n       0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 0, 2, 1, 0, 2, 2, 1, 2, 2,\n       2, 0, 2, 0, 0, 0, 1, 0, 2, 2, 0, 2, 2, 1, 2, 0, 0, 1, 2, 2, 1, 0,\n       2, 0, 1, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 2, 0, 1, 0, 0,\n       0, 2, 2, 2, 0, 0, 2, 0, 2, 1, 1, 0, 1, 2, 0, 0, 1, 1, 0, 0, 1, 0,\n       0, 2, 1, 2, 1, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 0, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0,\n       2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 1, 0, 2, 1, 1, 0, 2, 1, 0, 0, 0, 1,\n       0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1])\nX_train.to_csv(\"X_Train.csv\", index = False)\n\npd.DataFrame(y_train, columns=[\"Species\"]).to_csv(\"y_train.csv\", index=False)\nNow, I am going to merge the column with the species onto my new dataset.\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndf = X_train.copy()\ndf[\"Species\"] = y_train.flatten().astype(int)\n\n\nfig, ax = plt.subplots(figsize=(6, 5))\nsns.scatterplot(data=df, x=\"Flipper Length (mm)\", y=\"Body Mass (g)\", hue=\"Species\", style=\"Species\", ax=ax)\nax.set(title=\"Body Mass vs. Flipper Length by Species\", xlabel=\"Flipper Length (mm)\", ylabel=\"Body Mass (g)\")\nplt.tight_layout()\nplt.show()\n# Boxplot: Flipper Length Distribution (with hue)\nfig, ax = plt.subplots(figsize=(6, 5))\nsns.boxplot(data=df, x=\"Species\", y=\"Flipper Length (mm)\", ax=ax)\nax.set(title=\"Flipper Length by Species\", xlabel=\"Species\", ylabel=\"Flipper Length (mm)\")\nplt.tight_layout()\nplt.show()\nsummary_table = df.groupby(\"Species\").aggregate({\n    \"Culmen Length (mm)\": [\"mean\", \"std\"],\n    \"Culmen Depth (mm)\": [\"mean\", \"std\"],\n    \"Flipper Length (mm)\": [\"mean\", \"std\"],\n    \"Body Mass (g)\": [\"mean\", \"std\"]\n})\nsummary_table\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\nmean\nstd\nmean\nstd\nmean\nstd\nmean\nstd\n\n\nSpecies\n\n\n\n\n\n\n\n\n\n\n\n\n0\n38.961111\n2.685713\n18.380556\n1.218430\n190.527778\n6.652184\n3722.916667\n462.850335\n\n\n1\n48.771429\n3.456257\n18.346429\n1.137935\n195.821429\n7.366033\n3739.732143\n410.148997\n\n\n2\n47.133696\n2.783242\n14.926087\n1.016336\n216.739130\n6.061715\n5057.336957\n498.976123\nX_train\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n270\n51.1\n16.5\n225.0\n5250.0\n8.20660\n-26.36863\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n271\n35.9\n16.6\n190.0\n3050.0\n8.47781\n-26.07821\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\n272\n39.5\n17.8\n188.0\n3300.0\n9.66523\n-25.06020\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n273\n36.7\n19.3\n193.0\n3450.0\n8.76651\n-25.32426\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n274\n42.4\n17.3\n181.0\n3600.0\n9.35138\n-24.68790\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n\n\n256 rows × 14 columns\n# Re-import necessary libraries after execution state reset\nimport pandas as pd\nimport numpy as np\nfrom itertools import combinations\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nqualitative_features = [\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\", \"Clutch Completion_No\", \"Clutch Completion_Yes\", \"Sex_FEMALE\", \"Sex_MALE\"]\nquantitative_features = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]\n\n# Initialize variables\nbest_features = None\nbest_score = 0\n\n# Try combinations of 1 qualitative + 2 quantitative features\nfor qual in qualitative_features:\n    for quant_combo in combinations(quantitative_features, 2):\n        selected_features = [qual] + list(quant_combo)\n\n        # Train a Random Forest (instead of Decision Tree) with optimized hyperparameters\n        RF = RandomForestClassifier(random_state=7)\n        scores = cross_val_score(RF, X_train[selected_features], y_train, cv=5)\n\n        # Compute mean accuracy\n        mean_score = np.mean(scores)\n\n        # Track the best feature combination\n        if mean_score &gt; best_score:\n            best_score = mean_score\n            best_features = selected_features\n\n# Output the best feature set and corresponding accuracy\nbest_features, best_score\n\n(['Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)'],\n np.float64(0.9844645550527904))\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\ncols = ['Culmen Length (mm)', 'Flipper Length (mm)','Sex_MALE']\n\nRF = RandomForestClassifier(random_state=7)\nRF.fit(X_test[cols], y_test)\nRF.score(X_test[cols], y_test)\n\n1.0\nX_train\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n270\n51.1\n16.5\n225.0\n5250.0\n8.20660\n-26.36863\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n271\n35.9\n16.6\n190.0\n3050.0\n8.47781\n-26.07821\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\n272\n39.5\n17.8\n188.0\n3300.0\n9.66523\n-25.06020\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n273\n36.7\n19.3\n193.0\n3450.0\n8.76651\n-25.32426\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n274\n42.4\n17.3\n181.0\n3600.0\n9.35138\n-24.68790\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n\n\n256 rows × 14 columns\nNow regions…\nfrom matplotlib.patches import Patch\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\ncols = ['Culmen Length (mm)', 'Flipper Length (mm)','Sex_MALE', \"Island_Dream\"]\nRF = RandomForestClassifier()\nRF.fit(X_train[cols], y_train)\n\nplot_regions(RF, X_train[cols], y_train)\nJACKSON HANSONThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Classifying Palmer Penguins",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Classifying Palmer Penguins\n\n\n\n\n\nTEST TEST TEST\n\n\n\n\n\nFeb 12, 2025\n\n\nJackson Hanson\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  }
]